{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import xlwt\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import collections\n",
    "import jieba\n",
    "import jieba.analyse as analyse\n",
    "import json\n",
    "import seaborn as sns\n",
    "from openpyxl import load_workbook\n",
    "from operator import itemgetter\n",
    "from wordcloud import WordCloud\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "save_path = '/Users/priscilla/Desktop/python/Fuguo/xueqiu_result'\n",
    "os.chdir(save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article\n",
    "# read_path = '/Users/priscilla/Desktop/python/Fuguo/xueqiu_raw/article_data'\n",
    "def csv_file_name(read_path):\n",
    "    csv_file_name = []\n",
    "    for root, dirs, files in os.walk(read_path):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.csv':\n",
    "                csv_file_name.append(os.path.join(root, file))\n",
    "    return csv_file_name\n",
    "\n",
    "# csv_file_names = csv_file_name(read_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge article related csv into a single dataframe\n",
    "def merging_csv(csv_list):\n",
    "    frame = []\n",
    "\n",
    "    for i in range(0,len(csv_list)):\n",
    "        try: \n",
    "            df = pd.read_csv(csv_list[i], encoding = 'gb18030')\n",
    "            frame.append(df)\n",
    "        except:\n",
    "            df = pd.read_csv(csv_list[i])\n",
    "            frame.append(df)\n",
    "    result = pd.concat(frame,sort=True) \n",
    "    return result\n",
    "\n",
    "# article=merging_csv(csv_file_names)\n",
    "# article=article[['user_id','view_count','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article\n",
    "article=pd.read_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/article.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with article related info\n",
    "article['count_article']=1\n",
    "article=article.sort_values(by='view_count',ascending=False)\n",
    "grouped=article.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_article(x):\n",
    "    return(x.iloc[0])\n",
    "def best_four(x):\n",
    "    return(','.join(x.iloc[0:4]))\n",
    "article['best_4']=article['title']\n",
    "article=grouped.agg({'view_count':np.mean,'count_article':np.sum,'title':best_article,'best_4':best_four})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.loc[8417755168,'best_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock\n",
    "save_path = '/Users/priscilla/Desktop/python/Fuguo/xueqiu_result'\n",
    "watch_asset_final=pd.read_excel(save_path+'/'+'watch_asset_final.xlsx')\n",
    "watch_asset_final=watch_asset_final.drop([\"Unnamed: 0\",\"Unnamed: 0.1\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock related info: region(A,H,US), # stock, indu\n",
    "def region_per(x):\n",
    "    n=len(x)\n",
    "    dic={'A':sum(x=='A')/n,'H':sum(x=='H')/n,'US':sum(x=='US')/n}\n",
    "    return dic\n",
    "\n",
    "ls_US=['美国股票','美国基金']\n",
    "ls_A=['A股主板股票','A股基金','A股股转债','A股企业和国家债券','质押回购债券','A股三板股票','A股科创板股票']\n",
    "ls_H=['H股股票','H股股权','H股基金']\n",
    "\n",
    "def make_simple(x):    \n",
    "    if x in ls_US:\n",
    "        return 'US'\n",
    "    elif x in ls_A:\n",
    "        return 'A'\n",
    "    elif x in ls_H:\n",
    "        return 'H'\n",
    "    return '/'\n",
    "\n",
    "watch_asset_final['region']=watch_asset_final['type_chinese'].apply(make_simple)\n",
    "watch_asset_final['count_stock']=1\n",
    "grouped = watch_asset_final.groupby(by='uid')\n",
    "\n",
    "# number of stock & region\n",
    "stock_group = grouped.agg({'count_stock':np.sum,'region':region_per})\n",
    "stock_group['A']=stock_group['region'].apply(lambda x:x['A'])\n",
    "stock_group['H']=stock_group['region'].apply(lambda x:x['H'])\n",
    "stock_group['US']=stock_group['region'].apply(lambda x:x['US'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #重新爬取了每个用户的portfolio，将其合成一个portfolio列表用于后续portfolio每日数据爬取\n",
    "# csv_file_name=csv_file_name('/Users/priscilla/Desktop/python/Fuguo/xueqiu_raw/xueqiu')\n",
    "\n",
    "# #选取文件列表中的portfolio文件的目录存入列表portfolio\n",
    "# def portfolio(csv_file_names):\n",
    "#     portfolio = []\n",
    "#     for file in csv_file_names:\n",
    "#         if os.path.basename(file) == 'portfolio.csv':\n",
    "#             portfolio.append(file)\n",
    "#     return portfolio     \n",
    "# portfolio_list=portfolio(csv_file_name)\n",
    "# portfolio_raw = merging_csv(portfolio_list)\n",
    "# portfolio_raw.to_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/portfolio_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# portfolio\n",
    "\n",
    "# read csv\n",
    "read_path = '/Users/priscilla/Desktop/python/Fuguo/xueqiu_raw/portfolio_new'\n",
    "csv_file_names = csv_file_name(read_path)\n",
    "\n",
    "# merge csv\n",
    "#portfolio=merging_csv(csv_file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge article related csv into a single dataframe\n",
    "def merging_csv_withName(csv_list):\n",
    "    frame = []\n",
    "\n",
    "    for i in range(0,len(csv_list)):\n",
    "        try: \n",
    "            df = pd.read_csv(csv_list[i], encoding = 'gb18030')\n",
    "            df['portfolio_name']=re.search('portfolio_new/(.*)/portfolio_net_value\\.csv',csv_list[i]).group(1)\n",
    "            frame.append(df)\n",
    "            \n",
    "        except:\n",
    "            df = pd.read_csv(csv_list[i])\n",
    "            df['portfolio_name']=re.search('portfolio_new/(.*)/portfolio_net_value\\.csv',csv_list[i]).group(1)\n",
    "            frame.append(df)\n",
    "    result = pd.concat(frame,sort=True) \n",
    "    return result\n",
    "\n",
    "\n",
    "#get portfolio_net_value.csv\n",
    "def portfolio_net_value(csv_file_names):\n",
    "    portfolio_net_value= []\n",
    "    for file in csv_file_names:\n",
    "        if os.path.basename(file) == 'portfolio_net_value.csv':\n",
    "            portfolio_net_value.append(file)\n",
    "    return portfolio_net_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_temp_names=portfolio_net_value(csv_file_names)\n",
    "port_temp=merging_csv_withName(port_temp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time,datetime\n",
    "def get_time(x):\n",
    "    x=x//1000\n",
    "    dateArray=datetime.datetime.fromtimestamp(x)\n",
    "    #time=dateArray.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    return dateArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the portfolio has existed for 3y&1y\n",
    "port_temp['date_time']=port_temp['time'].apply(get_time)\n",
    "grouped=port_temp.groupby('portfolio_name')\n",
    "date_range=grouped['date_time'].apply(lambda x: x.iloc[-1]-x[0]).to_frame()\n",
    "date_range['3years']=(date_range['date_time']>datetime.timedelta(days=365*3+1))\n",
    "date_range['1year']=(date_range['date_time']>datetime.timedelta(days=365))\n",
    "date_range['exist_period']=date_range['date_time']\n",
    "date_range['exist_period']=date_range['date_time'].astype('timedelta64[D]').astype(int) \n",
    "date_range['exist_period']=date_range['exist_period'].apply(lambda x:x/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the 3 years and 1 year annual return\n",
    "temp=port_temp.merge(date_range,left_on='portfolio_name',right_index=True,how='left')\n",
    "temp['value_3y_before']=temp.groupby(\"portfolio_name\")['value'].shift(250*3)\n",
    "temp['value_1y_before']=temp.groupby(\"portfolio_name\")['value'].shift(250)\n",
    "\n",
    "temp['3y_return']=(temp['value']-temp['value_3y_before'])/3\n",
    "temp['1y_return']=(temp['value']-temp['value_1y_before'])\n",
    "\n",
    "temp=temp.groupby('portfolio_name').apply(lambda x:x.iloc[-1,])\n",
    "temp=temp[['exist_period','3years','1year','3y_return','1y_return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio=pd.read_excel(save_path+'/'+'portfolio_list.xlsx',index_col=0)\n",
    "portfolio.set_index('portfolio_name',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio\n",
    "portfolio=pd.read_excel(save_path+'/'+'portfolio_list.xlsx',index_col=0)\n",
    "portfolio.set_index('portfolio_name',inplace=True)\n",
    "portfolio=portfolio.merge(temp,left_index=True,right_index=True,how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port=portfolio[['uid','name','annualized_gain','monthly_gain','exist_period','3years','1year','3y_return','1y_return']]\n",
    "port['count_portfolio']=1\n",
    "grouped=port.groupby('uid')\n",
    "port=grouped.agg({'monthly_gain':np.mean,'count_portfolio':np.sum,'exist_period':np.mean,'annualized_gain':np.mean})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_name(x):\n",
    "    return(x[0])\n",
    "\n",
    "#1 year annualized_gain\n",
    "portfolio=portfolio.sort_values(by='annualized_gain',ascending=False)\n",
    "grouped=portfolio[portfolio['1year']].groupby('uid')\n",
    "port['1y_return']=grouped['1y_return'].mean()\n",
    "port['1y_return']=port['1y_return'].apply(lambda x:x*100)\n",
    "port['best_port']=grouped['name'].apply(first_name)\n",
    "\n",
    "#3 years annualized gain\n",
    "grouped=portfolio.groupby('uid')\n",
    "port['3y_return']=grouped['3y_return'].mean()\n",
    "port['3y_return']=port['3y_return'].apply(lambda x:x*100)\n",
    "\n",
    "portfolio=port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry\n",
    "indu=pd.read_excel(save_path+'/'+'industry_g.xlsx',index_col=0)\n",
    "indu=indu[['uid','INDUSTRY_GICS']]\n",
    "indu.set_index('uid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user\n",
    "user=pd.read_excel(\"/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/user_1.xlsx\")\n",
    "user=user[['id','screen_name','verified_description','description','followers_count','friends_count','个人身份认证','自媒体身份认证','达人认证','公司认证','实名认证','实盘认证','雪球官方账号认证']]\n",
    "user.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user['认证']=[[]]*len(user)\n",
    "user['认证'][user['个人身份认证']==True]=user['认证'][user['个人身份认证']==True].apply(lambda x:x+['个人身份认证'])\n",
    "user['认证'][user['自媒体身份认证']==True]=user['认证'][user['自媒体身份认证']==True].apply(lambda x:x+['自媒体身份认证'])\n",
    "user['认证'][user['达人认证']==True]=user['认证'][user['达人认证']==True].apply(lambda x:x+['达人认证'])\n",
    "user['认证'][user['公司认证']==True]=user['认证'][user['公司认证']==True].apply(lambda x:x+['公司认证'])\n",
    "user['认证'][user['实名认证']==True]=user['认证'][user['实名认证']==True].apply(lambda x:x+['实名认证'])\n",
    "user['认证'][user['实盘认证']==True]=user['认证'][user['实盘认证']==True].apply(lambda x:x+['实盘认证'])\n",
    "user['认证'][user['雪球官方账号认证']==True]=user['认证'][user['雪球官方账号认证']==True].apply(lambda x:x+['雪球官方账号认证'])\n",
    "user['认证']=user['认证'].apply(lambda x:','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# influence\n",
    "influ=pd.read_table('/Users/priscilla/Desktop/python/Fuguo/xueqiu_raw/part-00000',header=None)\n",
    "influ['user_id']=influ[0].apply(lambda x:int(re.split(',|\\(|\\)',x)[1]))\n",
    "influ['influence']=influ[0].apply(lambda x:float(re.split(',|\\(|\\)',x)[2]))\n",
    "influ.set_index('user_id',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet: only consider the last half year\n",
    "tweet=pd.read_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/tweet_simple.xlsx')\n",
    "tweet=tweet[['user_id','created_at','retweet_status_id']]\n",
    "\n",
    "# select the data after 2019-07-01\n",
    "tweet=tweet[tweet['created_at']>='2019-07-01 00:00:00']\n",
    "\n",
    "tweet['original']=(tweet['retweet_status_id']==0)+0\n",
    "tweet['retweet']=(tweet['retweet_status_id']!=0)+0\n",
    "tweet['count_tweet']=1\n",
    "grouped=tweet.groupby('user_id')\n",
    "tweet=grouped.sum()\n",
    "tweet['original_per']=tweet['original']/tweet['count_tweet']\n",
    "tweet['retweet_per']=tweet['retweet']/tweet['count_tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns\n",
    "stock_group=stock_group[['count_stock','A','H','US']]\n",
    "portfolio=portfolio[['count_portfolio','exist_period','annualized_gain','monthly_gain','1y_return','3y_return','best_port']]\n",
    "article=article[['count_article','view_count','title']]\n",
    "tweet=tweet[['count_tweet','original_per']]\n",
    "influ=influ[['influence']]\n",
    "user=user[['screen_name','verified_description','description','followers_count','friends_count','认证']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_influ\n",
    "user_influ=pd.merge(user,influ,left_index=True,right_index=True,how='left')\n",
    "user_influ.columns=['昵称','认证介绍','个人简介','粉丝数','关注数','认证','影响力']\n",
    "user_influ.sort_values(by='影响力',ascending=False,inplace=True)\n",
    "#user_influ.to_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/output_table/user_influ.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_id=user_influ[['昵称']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article_tweet\n",
    "article_tweet=pd.merge(name_id,article,left_index=True,right_index=True,how='left')\n",
    "article_tweet=pd.merge(article_tweet,tweet,left_index=True,right_index=True,how='left')\n",
    "article_tweet.columns=['昵称','发文数','平均文章阅读数','代表文章','发帖数（近半年）','原创比率']\n",
    "#article_tweet.to_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/output_table/article_tweet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region_indu\n",
    "region_indu=pd.merge(name_id,stock_group[['A','H','US','count_stock']],left_index=True,right_index=True,how='left')\n",
    "region_indu=pd.merge(region_indu,indu,left_index=True,right_index=True,how='left')\n",
    "region_indu.columns=['昵称','中国大陆','香港','美国','关注股票数','关注行业']\n",
    "#region_indu.to_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/output_table/region_indu.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio\n",
    "port=pd.merge(name_id,portfolio,left_index=True,right_index=True,how='left')\n",
    "port.columns=['昵称','创建组数','组合平均持续时间','年化总收益率','月收益率','近1年年化收益率','近3年年化收益率','代表型组合']\n",
    "port.to_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/output_table/portfolio.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate all\n",
    "result=pd.merge(user_influ,article_tweet.iloc[:,1:],left_index=True,right_index=True,how='left')\n",
    "result=pd.merge(result,region_indu.iloc[:,1:],left_index=True,right_index=True,how='left')\n",
    "result=pd.merge(result,port.iloc[:,1:],left_index=True,right_index=True,how='left')\n",
    "result.to_excel('/Users/priscilla/Desktop/python/Fuguo/xueqiu_result/output_table/aggregated_table_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
